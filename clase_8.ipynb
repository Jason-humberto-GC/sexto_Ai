{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al obtener la página: 403\n",
      "No se pudo obtener el texto de la página.\n",
      "No se pudo obtener el texto de la página.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def obtener_texto_pagina(url):\n",
    "    # Realizar la solicitud GET a la URL\n",
    "    respuesta = requests.get(url)\n",
    "    # Verificar si la solicitud fue exitosa\n",
    "    if respuesta.status_code == 200:\n",
    "        # Utilizar BeautifulSoup para analizar el HTML\n",
    "        soup = BeautifulSoup(respuesta.text, 'html.parser')\n",
    "        # Extraer todo el texto del HTML\n",
    "        texto = soup.get_text()\n",
    "        return texto\n",
    "    else:\n",
    "        print(\"Error al obtener la página:\", respuesta.status_code)\n",
    "        return None\n",
    "\n",
    "def analizar_texto(texto):\n",
    "    # Eliminar caracteres no deseados y dividir el texto en palabras\n",
    "    palabras = re.findall(r'\\b\\w+\\b', texto.lower())\n",
    "    # Contar la frecuencia de cada palabra\n",
    "    frecuencia_palabras = Counter(palabras)\n",
    "    return frecuencia_palabras\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # URL de la página a analizar\n",
    "    \n",
    "    url_pagina = input(\"Introduce la URL de la página a analizar: \")\n",
    "   \n",
    "    \n",
    "    \n",
    "    # Obtener el texto de la página\n",
    "    texto_pagina = obtener_texto_pagina(url_pagina)\n",
    "    \n",
    "    if texto_pagina:\n",
    "        # Imprimir el texto completo de la página\n",
    "        print(texto_pagina)\n",
    "    else:\n",
    "        print(\"No se pudo obtener el texto de la página.\")\n",
    "        \n",
    "    \n",
    "    if texto_pagina:\n",
    "        # Analizar el texto obtenido\n",
    "        frecuencia_palabras = analizar_texto(texto_pagina)\n",
    "        \n",
    "        \n",
    "        #palabras que hay en la pagina\n",
    "        print(f\"Se encontraron {len(frecuencia_palabras)} palabras en la página.\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Imprimir las 15 palabras más frecuentes\n",
    "        print(\"Las 15 palabras más frecuentes en la página:\")\n",
    "        for palabra, frecuencia in frecuencia_palabras.most_common(15):\n",
    "            print(f\"{palabra}: {frecuencia}\")\n",
    "    else:\n",
    "        print(\"No se pudo obtener el texto de la página.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
